{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-c87c188a67fd>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bsmt_data['BsmtQual'] = encoder1.fit_transform(bsmt_data['BsmtQual'].to_numpy().reshape(-1,1))\n",
      "/home/aaron/ml/env/lib/python3.8/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "Data = pd.read_csv('train.csv')\n",
    "train_outputs = Data['SalePrice']\n",
    "Data = Data.drop(['SalePrice'], axis=1)\n",
    "\n",
    "def clean_data(Data):\n",
    "    # For some features, 'NA' is an acceptable value, so change the pd.NA \n",
    "    # for those to 'NA' where necessary\n",
    "    # list of columns that are supposed to have NA\n",
    "    acceptable_na = ['Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
    "                     'BsmtFinType2', 'FireplaceQu', 'GarageType', 'GarageFinish', \n",
    "                     'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "\n",
    "    for feature in acceptable_na:\n",
    "        Data[feature].fillna('NA', inplace=True)\n",
    "\n",
    "    remove_columns = ['Id', 'Utilities', 'Condition1', 'Condition2', 'PoolArea', 'PoolQC', 'MiscFeature']\n",
    "    Data = Data.drop(remove_columns, axis=1)\n",
    "\n",
    "    bsmt_cols = [col for col in Data if col.startswith('Bsmt')]\n",
    "    bsmt_cols.append('TotalBsmtSF')\n",
    "    bsmt_data = Data[bsmt_cols]\n",
    "\n",
    "    cats1 = ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "    encoder1 = preprocessing.OrdinalEncoder(categories=[cats1])\n",
    "\n",
    "    bsmt_data['BsmtQual'] = encoder1.fit_transform(bsmt_data['BsmtQual'].to_numpy().reshape(-1,1))\n",
    "\n",
    "    Data = Data.drop(bsmt_cols, axis=1)\n",
    "    Data['BsmtQual'] = bsmt_data['BsmtQual']\n",
    "    Data['TotalBsmtSF'] = bsmt_data['TotalBsmtSF']\n",
    "\n",
    "    gar_cols = [col for col in Data if col.startswith('Garage')]\n",
    "    gar_data = Data[gar_cols]\n",
    "    # fill missing data for garage year built with the median year\n",
    "    gar_data['GarageYrBlt'].fillna(gar_data['GarageYrBlt'].median(), inplace=True)\n",
    "\n",
    "    Data = Data.drop(gar_cols, axis=1)\n",
    "    Data['GarageYrBlt'] = gar_data['GarageYrBlt']\n",
    "    Data['GarageCars'] = gar_data['GarageCars']\n",
    "    Data['GarageArea'] = gar_data['GarageArea']\n",
    "\n",
    "    one_hot_cols = ['MSZoning', 'Street', 'Alley', 'LotConfig', 'BldgType',\n",
    "                    'RoofStyle', 'RoofMatl', 'MasVnrType', 'Foundation', 'Heating', 'Electrical', 'SaleCondition']\n",
    "    Data['MasVnrType'] = Data['MasVnrType'].replace(np.nan, 'None')\n",
    "    Data['Electrical'] = Data['Electrical'].replace(np.nan, 'None')\n",
    "    one_hot_enc = preprocessing.OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    temp = pd.DataFrame(\n",
    "        one_hot_enc.fit_transform(Data[one_hot_cols]),\n",
    "        columns=one_hot_enc.get_feature_names(one_hot_cols)\n",
    "    )\n",
    "    Data = Data.drop(one_hot_cols, axis=1)\n",
    "    Data = pd.concat([Data, temp], axis=1)\n",
    "\n",
    "    unsure_cols = ['MSSubClass', 'LandContour', 'Neighborhood', 'Exterior1st', 'Exterior2nd',\n",
    "                   'Fence', 'SaleType', 'HouseStyle', 'Functional']\n",
    "    Data = Data.drop(unsure_cols, axis=1)\n",
    "\n",
    "    ords = [\n",
    "        'LotShape', 'LandSlope', 'ExterQual', 'ExterCond', 'HeatingQC', 'CentralAir', 'KitchenQual', 'FireplaceQu',\n",
    "        'PavedDrive'\n",
    "    ]\n",
    "    lot_shape_cats = ['IR3', 'IR2', 'IR1', 'Reg']\n",
    "    land_slope_cats = ['Gtl', 'Mod', 'Sev']\n",
    "    qual_cond_cats = ['Po', 'Fa', 'TA', 'Gd', 'Ex'] #x3\n",
    "    central_air_cats = ['N', 'Y'] \n",
    "    # qual_cond_cats again\n",
    "    qual_cond_na_cats = ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "    paved_drive_cats = ['N', 'P', 'Y']\n",
    "\n",
    "    CATS = [lot_shape_cats, land_slope_cats, qual_cond_cats, qual_cond_cats, qual_cond_cats, central_air_cats,\n",
    "           qual_cond_cats, qual_cond_na_cats, paved_drive_cats]\n",
    "\n",
    "    encoder1 = preprocessing.OrdinalEncoder(categories=CATS)\n",
    "    Data[ords] = encoder1.fit_transform(Data[ords])\n",
    "\n",
    "    Data['MasVnrArea'] = Data['MasVnrArea'].replace(np.nan, 0)\n",
    "\n",
    "    Data['NumBath'] = Data.FullBath + .5*Data.HalfBath\n",
    "    Data = Data.drop(['FullBath', 'HalfBath'], axis=1)\n",
    "\n",
    "    Data['DateSold'] = Data.YrSold + (1/12)*Data.MoSold\n",
    "    Data = Data.drop(['YrSold', 'MoSold'], axis=1)\n",
    "\n",
    "    # fill missing data for garage year built with the median year\n",
    "    Data['LotFrontage'].fillna(Data['LotFrontage'].median(), inplace=True)\n",
    "    \n",
    "    for col in Data.columns:\n",
    "        if Data[col].isnull().values.any():\n",
    "            Data[col].fillna(Data[col].median(), inplace=True)\n",
    "    \n",
    "    return Data\n",
    "\n",
    "Data = clean_data(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>...</th>\n",
       "      <th>Electrical_None</th>\n",
       "      <th>Electrical_SBrkr</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>NumBath</th>\n",
       "      <th>DateSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2008.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2007.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2008.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2006.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2007.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>1988</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1941</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2008.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotFrontage  LotArea  LotShape  LandSlope  OverallQual  OverallCond  \\\n",
       "0            65.0     8450       3.0        0.0            7            5   \n",
       "1            80.0     9600       3.0        0.0            6            8   \n",
       "2            68.0    11250       2.0        0.0            7            5   \n",
       "3            60.0     9550       2.0        0.0            7            5   \n",
       "4            84.0    14260       2.0        0.0            8            5   \n",
       "...           ...      ...       ...        ...          ...          ...   \n",
       "1455         62.0     7917       3.0        0.0            6            5   \n",
       "1456         85.0    13175       3.0        0.0            6            6   \n",
       "1457         66.0     9042       3.0        0.0            7            9   \n",
       "1458         68.0     9717       3.0        0.0            5            6   \n",
       "1459         75.0     9937       3.0        0.0            5            6   \n",
       "\n",
       "      YearBuilt  YearRemodAdd  MasVnrArea  ExterQual  ...  Electrical_None  \\\n",
       "0          2003          2003       196.0        3.0  ...              0.0   \n",
       "1          1976          1976         0.0        2.0  ...              0.0   \n",
       "2          2001          2002       162.0        3.0  ...              0.0   \n",
       "3          1915          1970         0.0        2.0  ...              0.0   \n",
       "4          2000          2000       350.0        3.0  ...              0.0   \n",
       "...         ...           ...         ...        ...  ...              ...   \n",
       "1455       1999          2000         0.0        2.0  ...              0.0   \n",
       "1456       1978          1988       119.0        2.0  ...              0.0   \n",
       "1457       1941          2006         0.0        4.0  ...              0.0   \n",
       "1458       1950          1996         0.0        2.0  ...              0.0   \n",
       "1459       1965          1965         0.0        3.0  ...              0.0   \n",
       "\n",
       "      Electrical_SBrkr  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
       "0                  1.0                    0.0                    0.0   \n",
       "1                  1.0                    0.0                    0.0   \n",
       "2                  1.0                    0.0                    0.0   \n",
       "3                  1.0                    1.0                    0.0   \n",
       "4                  1.0                    0.0                    0.0   \n",
       "...                ...                    ...                    ...   \n",
       "1455               1.0                    0.0                    0.0   \n",
       "1456               1.0                    0.0                    0.0   \n",
       "1457               1.0                    0.0                    0.0   \n",
       "1458               0.0                    0.0                    0.0   \n",
       "1459               1.0                    0.0                    0.0   \n",
       "\n",
       "      SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "0                      0.0                   0.0                   1.0   \n",
       "1                      0.0                   0.0                   1.0   \n",
       "2                      0.0                   0.0                   1.0   \n",
       "3                      0.0                   0.0                   0.0   \n",
       "4                      0.0                   0.0                   1.0   \n",
       "...                    ...                   ...                   ...   \n",
       "1455                   0.0                   0.0                   1.0   \n",
       "1456                   0.0                   0.0                   1.0   \n",
       "1457                   0.0                   0.0                   1.0   \n",
       "1458                   0.0                   0.0                   1.0   \n",
       "1459                   0.0                   0.0                   1.0   \n",
       "\n",
       "      SaleCondition_Partial  NumBath     DateSold  \n",
       "0                       0.0      2.5  2008.166667  \n",
       "1                       0.0      2.0  2007.416667  \n",
       "2                       0.0      2.5  2008.750000  \n",
       "3                       0.0      1.0  2006.166667  \n",
       "4                       0.0      2.5  2009.000000  \n",
       "...                     ...      ...          ...  \n",
       "1455                    0.0      2.5  2007.666667  \n",
       "1456                    0.0      2.0  2010.166667  \n",
       "1457                    0.0      2.0  2010.416667  \n",
       "1458                    0.0      1.0  2010.333333  \n",
       "1459                    0.0      1.5  2008.500000  \n",
       "\n",
       "[1460 rows x 99 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = GridSearchCV(\n",
    "    estimator=rf_reg,\n",
    "    param_grid={\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'criterion': ['mse', 'mae'],\n",
    "        'min_samples_split': [2, 4, 8],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['mse', 'mae'],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 4, 8],\n",
       "                         'n_estimators': [50, 100, 150]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(Data,train_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.74042134,  1.4733438 ,  2.21881924,  0.65676003,  1.31593351,\n",
       "         1.97378473,  0.57965717,  1.162606  ,  1.75384021,  0.61933079,\n",
       "         1.23677039,  1.85047402,  0.61825857,  1.22895923,  1.85859971,\n",
       "         0.55454297,  1.09961634,  1.68519745,  0.51049528,  1.01970153,\n",
       "         1.5366837 ,  0.51044183,  1.02419791,  1.53564854,  0.51230264,\n",
       "         1.01601715,  1.52354574, 10.23195443, 20.41934085, 30.63852539,\n",
       "        10.00761518, 20.07615061, 30.14794993,  9.70747747, 19.43351822,\n",
       "        29.13558722,  8.73167534, 17.38640122, 26.22050648,  8.72461405,\n",
       "        17.48721476, 26.26431475,  8.62615614, 17.10209165, 25.58232255,\n",
       "         7.37750926, 14.81550875, 22.14520917,  7.39030137, 14.76880488,\n",
       "        19.4095448 ,  7.40996423, 12.60256219, 16.16491237]),\n",
       " 'std_fit_time': array([0.00539901, 0.01240817, 0.01614257, 0.00585629, 0.01862906,\n",
       "        0.0116895 , 0.00228298, 0.01337231, 0.00815674, 0.01195457,\n",
       "        0.00759323, 0.01424722, 0.00963321, 0.01618798, 0.01453189,\n",
       "        0.00886928, 0.00535664, 0.01152345, 0.00823319, 0.00778413,\n",
       "        0.0134604 , 0.00931246, 0.00795183, 0.01334232, 0.00888054,\n",
       "        0.01266309, 0.00821166, 0.11883653, 0.22790624, 0.33719753,\n",
       "        0.09003795, 0.22767099, 0.25386705, 0.17368554, 0.17409808,\n",
       "        0.27562548, 0.12425054, 0.1313584 , 0.16168889, 0.07440432,\n",
       "        0.11145998, 0.1439206 , 0.08968429, 0.14164044, 0.19027839,\n",
       "        0.03408855, 0.09470736, 0.10906673, 0.04371389, 0.10888957,\n",
       "        0.74845407, 0.04318993, 1.21181375, 0.78910217]),\n",
       " 'mean_score_time': array([0.01155701, 0.01709929, 0.02096553, 0.01016707, 0.01363616,\n",
       "        0.02215223, 0.00830259, 0.0126863 , 0.01774259, 0.00852842,\n",
       "        0.01330013, 0.01830678, 0.008394  , 0.01385231, 0.0183619 ,\n",
       "        0.00789576, 0.01247296, 0.01699209, 0.00769668, 0.01227546,\n",
       "        0.01754661, 0.00771694, 0.01408992, 0.01632571, 0.00773249,\n",
       "        0.01193843, 0.01638746, 0.0087913 , 0.01456342, 0.02000809,\n",
       "        0.00816336, 0.01332359, 0.01855617, 0.00782804, 0.01266036,\n",
       "        0.01707559, 0.00786362, 0.01271877, 0.01813259, 0.00786581,\n",
       "        0.01290417, 0.01749921, 0.00972552, 0.01215339, 0.0165833 ,\n",
       "        0.00740333, 0.01179972, 0.0152823 , 0.00793538, 0.01082592,\n",
       "        0.01272497, 0.00736217, 0.0092638 , 0.0116477 ]),\n",
       " 'std_score_time': array([1.86108748e-03, 2.54728433e-03, 2.61609501e-04, 2.72483979e-03,\n",
       "        9.18989539e-05, 6.40420364e-03, 5.50547180e-04, 2.34361578e-04,\n",
       "        6.09918034e-04, 4.55636092e-04, 1.15363692e-04, 1.56315439e-04,\n",
       "        1.60463887e-04, 7.60082235e-04, 2.69567378e-04, 1.34648665e-04,\n",
       "        9.43746871e-05, 2.38530705e-04, 7.20607130e-05, 1.59026157e-04,\n",
       "        1.10275699e-03, 1.24661267e-04, 1.97304235e-03, 2.47884383e-04,\n",
       "        7.29873378e-05, 2.58087714e-04, 3.84441631e-04, 1.36191037e-04,\n",
       "        2.36625826e-04, 3.64684173e-04, 6.06732142e-05, 2.38515615e-04,\n",
       "        1.80256076e-04, 6.82267831e-05, 5.97618331e-04, 1.78237010e-04,\n",
       "        6.63032767e-05, 1.48848108e-04, 1.14885005e-03, 4.36925969e-05,\n",
       "        1.24240834e-04, 1.52142067e-04, 4.33180346e-03, 2.17029278e-04,\n",
       "        1.39201467e-04, 6.34195930e-05, 9.31048942e-05, 1.22967530e-03,\n",
       "        1.09707425e-03, 1.12397015e-03, 1.03431860e-04, 7.75706343e-05,\n",
       "        6.68544402e-05, 4.44556845e-04]),\n",
       " 'param_criterion': masked_array(data=['mse', 'mse', 'mse', 'mse', 'mse', 'mse', 'mse', 'mse',\n",
       "                    'mse', 'mse', 'mse', 'mse', 'mse', 'mse', 'mse', 'mse',\n",
       "                    'mse', 'mse', 'mse', 'mse', 'mse', 'mse', 'mse', 'mse',\n",
       "                    'mse', 'mse', 'mse', 'mae', 'mae', 'mae', 'mae', 'mae',\n",
       "                    'mae', 'mae', 'mae', 'mae', 'mae', 'mae', 'mae', 'mae',\n",
       "                    'mae', 'mae', 'mae', 'mae', 'mae', 'mae', 'mae', 'mae',\n",
       "                    'mae', 'mae', 'mae', 'mae', 'mae', 'mae'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 2, 2, 4, 4, 4, 8, 8, 8, 2, 2, 2, 4, 4, 4, 8, 8, 8,\n",
       "                    2, 2, 2, 4, 4, 4, 8, 8, 8, 2, 2, 2, 4, 4, 4, 8, 8, 8,\n",
       "                    2, 2, 2, 4, 4, 4, 8, 8, 8, 2, 2, 2, 4, 4, 4, 8, 8, 8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
       "                    50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
       "                    50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
       "                    50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
       "                    50, 100, 150, 50, 100, 150],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'mse',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mse',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'mae',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 150}],\n",
       " 'split0_test_score': array([0.86546349, 0.85935982, 0.85680899, 0.85495953, 0.86098947,\n",
       "        0.86512283, 0.85946082, 0.86225405, 0.85878317, 0.86339166,\n",
       "        0.86409271, 0.86327929, 0.84740949, 0.85424602, 0.86313457,\n",
       "        0.85968793, 0.85955437, 0.86109463, 0.8495039 , 0.86086657,\n",
       "        0.86365783, 0.85399965, 0.85786219, 0.85885648, 0.860062  ,\n",
       "        0.85583621, 0.85469028, 0.86378535, 0.86883985, 0.86638748,\n",
       "        0.85599218, 0.86539925, 0.8697503 , 0.86828099, 0.86571928,\n",
       "        0.86765309, 0.86511015, 0.86192069, 0.86971968, 0.86342083,\n",
       "        0.86878462, 0.86149011, 0.85602703, 0.85727015, 0.85768941,\n",
       "        0.85543348, 0.8553579 , 0.86001918, 0.85815459, 0.85501829,\n",
       "        0.85583358, 0.85311099, 0.85609683, 0.85870712]),\n",
       " 'split1_test_score': array([0.81299144, 0.81848519, 0.82029793, 0.82330475, 0.81293691,\n",
       "        0.82674227, 0.8314609 , 0.83267999, 0.83210895, 0.83167511,\n",
       "        0.82838885, 0.82571192, 0.8168776 , 0.82442612, 0.83128498,\n",
       "        0.8236474 , 0.83136435, 0.82856905, 0.81206775, 0.82552234,\n",
       "        0.82190194, 0.81533855, 0.82259144, 0.82763433, 0.82793376,\n",
       "        0.82017572, 0.8299312 , 0.82598699, 0.81367266, 0.81215201,\n",
       "        0.82613505, 0.82646755, 0.81587626, 0.82140239, 0.82583872,\n",
       "        0.83189988, 0.82363358, 0.8200753 , 0.83057898, 0.83154832,\n",
       "        0.82858305, 0.81445435, 0.82424556, 0.81516102, 0.82803311,\n",
       "        0.82593889, 0.81484732, 0.82289173, 0.82631587, 0.81891792,\n",
       "        0.81972637, 0.8395772 , 0.82441956, 0.82441156]),\n",
       " 'split2_test_score': array([0.858763  , 0.87311439, 0.87391826, 0.87395994, 0.86357637,\n",
       "        0.86761686, 0.86264395, 0.86420117, 0.86461312, 0.87145542,\n",
       "        0.86770699, 0.86903786, 0.86747181, 0.86132991, 0.87134029,\n",
       "        0.86618352, 0.8599165 , 0.86825466, 0.84683633, 0.84755515,\n",
       "        0.85170957, 0.84754753, 0.84722366, 0.8494988 , 0.84577447,\n",
       "        0.84055487, 0.84848234, 0.86933813, 0.8640736 , 0.86473294,\n",
       "        0.86164696, 0.86322581, 0.8584931 , 0.860126  , 0.86326615,\n",
       "        0.85872126, 0.87106241, 0.85856134, 0.85998125, 0.87232575,\n",
       "        0.85770887, 0.86531539, 0.85030418, 0.85790559, 0.8599496 ,\n",
       "        0.83589588, 0.83986087, 0.83612972, 0.82835678, 0.82879562,\n",
       "        0.83741462, 0.83981907, 0.84108372, 0.83728084]),\n",
       " 'split3_test_score': array([0.87230959, 0.87257802, 0.87691901, 0.87801648, 0.88228471,\n",
       "        0.8772858 , 0.87360406, 0.87101014, 0.87372728, 0.87373275,\n",
       "        0.87500902, 0.87194222, 0.87295584, 0.87610149, 0.87702199,\n",
       "        0.86809156, 0.86948003, 0.87639839, 0.85983642, 0.86712898,\n",
       "        0.87459682, 0.87761249, 0.87517241, 0.87136159, 0.86876576,\n",
       "        0.86501417, 0.87462153, 0.88309254, 0.87772787, 0.88216075,\n",
       "        0.8747874 , 0.87813807, 0.87612629, 0.87464117, 0.8731882 ,\n",
       "        0.87589334, 0.87625131, 0.87253714, 0.87336149, 0.87520248,\n",
       "        0.87708498, 0.87662185, 0.87948693, 0.87496434, 0.87532616,\n",
       "        0.87610981, 0.88446984, 0.87607592, 0.87998736, 0.88319013,\n",
       "        0.87488066, 0.86735335, 0.87799048, 0.87715475]),\n",
       " 'split4_test_score': array([0.81725996, 0.81434165, 0.82261143, 0.81054665, 0.82469017,\n",
       "        0.82015937, 0.80315071, 0.82097322, 0.81171881, 0.78432942,\n",
       "        0.80171115, 0.80979295, 0.8039995 , 0.80148354, 0.80765595,\n",
       "        0.81858874, 0.80582631, 0.80083145, 0.79356645, 0.79287051,\n",
       "        0.786083  , 0.79836555, 0.79782468, 0.79288802, 0.79364482,\n",
       "        0.7920184 , 0.78232188, 0.81947914, 0.8318317 , 0.83064565,\n",
       "        0.8296095 , 0.8331325 , 0.84367237, 0.82320691, 0.81370936,\n",
       "        0.82240355, 0.79795931, 0.81730371, 0.81499913, 0.78749727,\n",
       "        0.80853574, 0.80966467, 0.81466581, 0.80312899, 0.79507924,\n",
       "        0.80666442, 0.79616054, 0.79604253, 0.8071465 , 0.80676869,\n",
       "        0.80391032, 0.79810451, 0.80249906, 0.80757716]),\n",
       " 'mean_test_score': array([0.84535749, 0.84757582, 0.85011112, 0.84815747, 0.84889553,\n",
       "        0.85138543, 0.84606409, 0.85022371, 0.84819027, 0.84491687,\n",
       "        0.84738174, 0.84795285, 0.84174285, 0.84351742, 0.85008756,\n",
       "        0.84723983, 0.84522831, 0.84702964, 0.83236217, 0.83878871,\n",
       "        0.83958983, 0.83857275, 0.84013488, 0.84004784, 0.83923616,\n",
       "        0.83471987, 0.83800945, 0.85233643, 0.85122913, 0.85121577,\n",
       "        0.84963422, 0.85327264, 0.85278366, 0.84953149, 0.84834434,\n",
       "        0.85131423, 0.84680335, 0.84607964, 0.8497281 , 0.84599893,\n",
       "        0.84813945, 0.84550928, 0.8449459 , 0.84168602, 0.8432155 ,\n",
       "        0.8400085 , 0.8381393 , 0.83823182, 0.83999222, 0.83853813,\n",
       "        0.83835311, 0.83959303, 0.84041793, 0.84102629]),\n",
       " 'std_test_score': array([0.02508947, 0.02594982, 0.02439411, 0.02696601, 0.02590579,\n",
       "        0.02326094, 0.02556414, 0.0196751 , 0.02290343, 0.03382943,\n",
       "        0.02793626, 0.02532116, 0.02724402, 0.02692744, 0.0264626 ,\n",
       "        0.02156896, 0.0234685 , 0.02823443, 0.02519979, 0.02702566,\n",
       "        0.03202339, 0.02828103, 0.02716638, 0.02757456, 0.02666375,\n",
       "        0.02620168, 0.03128814, 0.0250598 , 0.02434769, 0.02576662,\n",
       "        0.01881814, 0.01994266, 0.02149658, 0.02270909, 0.02386567,\n",
       "        0.02068187, 0.0307031 , 0.02285174, 0.02296135, 0.03310811,\n",
       "        0.02571594, 0.02780254, 0.02319471, 0.02758118, 0.02852446,\n",
       "        0.02394966, 0.03082432, 0.02802334, 0.02580988, 0.02740278,\n",
       "        0.02519512, 0.02312886, 0.02589114, 0.02460406]),\n",
       " 'rank_test_score': array([29, 20,  9, 17, 14,  4, 26,  8, 16, 32, 21, 19, 35, 33, 10, 22, 30,\n",
       "        23, 54, 46, 44, 47, 39, 40, 45, 53, 52,  3,  6,  7, 12,  1,  2, 13,\n",
       "        15,  5, 24, 25, 11, 27, 18, 28, 31, 36, 34, 41, 51, 50, 42, 48, 49,\n",
       "        43, 38, 37], dtype=int32)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(criterion='mae', min_samples_split=4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb_reg = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = GridSearchCV(\n",
    "    estimator=gb_reg,\n",
    "    param_grid={\n",
    "        'loss': ['ls', 'lad', 'huber', 'quantile'],\n",
    "        'learning_rate': [.01, .1, .2],\n",
    "        'n_estimators': [100, 150, 200],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'loss': ['ls', 'lad', 'huber', 'quantile'],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'n_estimators': [100, 150, 200]})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg2.fit(Data,train_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.53050075, 0.80108018, 1.03759928, 0.53545127, 0.80071311,\n",
       "        1.05165577, 0.54840441, 0.78908687, 1.04167299, 0.65962048,\n",
       "        0.99053173, 1.3232121 , 0.67607751, 0.99678664, 1.33715219,\n",
       "        0.67079105, 1.00147257, 1.34272408, 0.73695641, 1.10127344,\n",
       "        1.46960378, 0.71972737, 1.09510794, 1.46022515, 0.73216758,\n",
       "        1.07254601, 1.43908911, 0.68015704, 1.00385518, 1.32523861,\n",
       "        0.67816739, 0.99568257, 1.334904  , 0.67029014, 0.98946009,\n",
       "        1.30807166, 0.5292521 , 0.8056879 , 1.04652991, 0.54721942,\n",
       "        0.79234376, 1.06160855, 0.52335925, 0.78101902, 1.04966807,\n",
       "        0.65672603, 0.95982056, 1.2961494 , 0.66475306, 0.96451173,\n",
       "        1.2832202 , 0.65960712, 0.97743573, 1.31345925, 0.71481428,\n",
       "        1.04964881, 1.41984034, 0.70978065, 1.0967082 , 1.41485519,\n",
       "        0.72996416, 1.04095812, 1.41016264, 0.67941713, 0.95909653,\n",
       "        1.25946546, 0.6459918 , 0.96688857, 1.30279131, 0.65668721,\n",
       "        0.99672441, 1.28604884, 0.52667322, 0.78637528, 1.06265049,\n",
       "        0.52770467, 0.7925241 , 1.06009521, 0.52619405, 0.7894743 ,\n",
       "        1.06112432, 0.63838606, 0.96813703, 1.28379688, 0.64224653,\n",
       "        0.95766153, 1.2713469 , 0.65535221, 0.9642478 , 1.27923689,\n",
       "        0.72445636, 1.1037117 , 1.42108159, 0.71677127, 1.08179498,\n",
       "        1.40758877, 0.71522117, 1.0355464 , 1.38706417, 0.63910832,\n",
       "        0.93894558, 1.23454018, 0.64086609, 0.9543704 , 1.23251686,\n",
       "        0.64521585, 0.9095376 , 1.04000645]),\n",
       " 'std_fit_time': array([0.01111756, 0.0206633 , 0.01348342, 0.01495899, 0.01478742,\n",
       "        0.03187295, 0.02009389, 0.00633546, 0.01309156, 0.0128217 ,\n",
       "        0.01307535, 0.01219291, 0.02551928, 0.00374683, 0.03284599,\n",
       "        0.01870197, 0.00860502, 0.00832556, 0.0414093 , 0.05672064,\n",
       "        0.04329965, 0.00508911, 0.035882  , 0.0377824 , 0.01088364,\n",
       "        0.00651527, 0.01336787, 0.01748518, 0.01892266, 0.00998262,\n",
       "        0.01237739, 0.01801038, 0.0222064 , 0.00557529, 0.00721505,\n",
       "        0.01362424, 0.00759437, 0.02201449, 0.01594063, 0.04244985,\n",
       "        0.01055461, 0.02603882, 0.00881948, 0.0134001 , 0.01042742,\n",
       "        0.01081791, 0.00549791, 0.02382722, 0.01916328, 0.0094348 ,\n",
       "        0.00919679, 0.01535005, 0.01480781, 0.03296049, 0.01515207,\n",
       "        0.00769387, 0.01055033, 0.01367409, 0.05202454, 0.02300825,\n",
       "        0.02023299, 0.01390929, 0.03337191, 0.02990239, 0.00906518,\n",
       "        0.00709725, 0.01327127, 0.00731364, 0.02841903, 0.00246251,\n",
       "        0.04534393, 0.01412559, 0.00830774, 0.01218662, 0.02722708,\n",
       "        0.00798895, 0.01205723, 0.02652801, 0.00655542, 0.00665662,\n",
       "        0.0165339 , 0.00752007, 0.00329656, 0.02658345, 0.00731723,\n",
       "        0.01280392, 0.00899426, 0.02873848, 0.01544421, 0.01327117,\n",
       "        0.02758261, 0.03197511, 0.00754768, 0.00956505, 0.03406168,\n",
       "        0.01065786, 0.01007767, 0.00490933, 0.00657786, 0.01129784,\n",
       "        0.0134986 , 0.0048208 , 0.00855993, 0.01283843, 0.02129278,\n",
       "        0.00562649, 0.03457407, 0.03519765]),\n",
       " 'mean_score_time': array([0.00374708, 0.00389099, 0.00646901, 0.00520473, 0.00387292,\n",
       "        0.00602279, 0.00364847, 0.00421848, 0.00422316, 0.00388365,\n",
       "        0.0038825 , 0.00636544, 0.0040689 , 0.00769548, 0.00437374,\n",
       "        0.00515032, 0.00424509, 0.00460057, 0.00380893, 0.00440722,\n",
       "        0.00454183, 0.00374708, 0.0040668 , 0.00470786, 0.00390663,\n",
       "        0.00395083, 0.00421286, 0.00358176, 0.00349889, 0.0039957 ,\n",
       "        0.00334768, 0.0036097 , 0.00371366, 0.00335298, 0.00536642,\n",
       "        0.00374875, 0.00345721, 0.00351629, 0.00533819, 0.00358086,\n",
       "        0.00357981, 0.00415206, 0.00329552, 0.00385499, 0.00382652,\n",
       "        0.00350165, 0.00374093, 0.00415182, 0.00336962, 0.00366087,\n",
       "        0.00385942, 0.00366764, 0.00377874, 0.00422711, 0.00346022,\n",
       "        0.00357332, 0.00500288, 0.0034296 , 0.0037941 , 0.0038394 ,\n",
       "        0.00372448, 0.00366559, 0.00376267, 0.00339475, 0.00352921,\n",
       "        0.0037828 , 0.00344815, 0.00355473, 0.00374379, 0.00348358,\n",
       "        0.00358229, 0.00384173, 0.00334888, 0.00352902, 0.00373039,\n",
       "        0.00328102, 0.00365305, 0.00385742, 0.00326633, 0.00348992,\n",
       "        0.0038578 , 0.00338707, 0.00533075, 0.00398955, 0.0032948 ,\n",
       "        0.00366545, 0.00397811, 0.00357137, 0.00365252, 0.00422339,\n",
       "        0.00347757, 0.00388045, 0.00445704, 0.0034514 , 0.00348411,\n",
       "        0.00420666, 0.00352407, 0.003513  , 0.00407867, 0.00357566,\n",
       "        0.00358305, 0.00391331, 0.00353465, 0.00376678, 0.00352817,\n",
       "        0.00320463, 0.002917  , 0.00263362]),\n",
       " 'std_score_time': array([2.18646585e-04, 6.44150350e-05, 3.94833618e-03, 3.23436507e-03,\n",
       "        8.05026820e-05, 3.79523706e-03, 2.17591062e-04, 5.35935345e-04,\n",
       "        1.33001449e-04, 6.62958508e-04, 3.59301149e-05, 4.14040959e-03,\n",
       "        4.72871825e-04, 4.61784026e-03, 2.58811704e-04, 2.78479399e-03,\n",
       "        5.68832643e-04, 5.57605173e-04, 2.63980229e-04, 4.90599569e-04,\n",
       "        3.41423344e-04, 2.34362315e-04, 2.05991257e-04, 4.57535563e-04,\n",
       "        3.54186944e-04, 3.98157599e-05, 1.53145071e-04, 5.54437246e-04,\n",
       "        5.42435750e-05, 1.51512364e-04, 1.20472547e-04, 1.51552577e-04,\n",
       "        6.40533422e-05, 8.69391444e-05, 3.49707811e-03, 4.01902164e-05,\n",
       "        3.13872698e-04, 4.63540168e-05, 3.19167721e-03, 4.96485299e-04,\n",
       "        1.13029358e-04, 6.37907111e-04, 7.34622699e-05, 5.04459662e-04,\n",
       "        1.30349750e-04, 1.14275992e-04, 1.21751813e-04, 4.77356818e-04,\n",
       "        1.09658178e-04, 1.40180993e-04, 1.01444413e-04, 2.54813140e-05,\n",
       "        1.75525656e-04, 4.74427127e-04, 1.38949022e-04, 2.73334605e-05,\n",
       "        2.14429644e-03, 1.31759987e-04, 3.22993195e-04, 1.32461861e-04,\n",
       "        3.10277855e-04, 9.45040964e-05, 4.86073214e-05, 1.20670575e-04,\n",
       "        1.78671564e-04, 1.27907370e-04, 1.32783832e-04, 8.49295839e-05,\n",
       "        6.09789903e-05, 1.26197492e-04, 9.00835378e-05, 7.05444437e-05,\n",
       "        1.01938417e-04, 6.28838483e-05, 5.35699755e-05, 5.08489541e-05,\n",
       "        1.50175470e-04, 9.84541605e-05, 5.13735334e-05, 2.70545318e-05,\n",
       "        8.70866280e-05, 8.67034462e-05, 3.11944638e-03, 2.17136459e-04,\n",
       "        7.63268102e-05, 1.90977360e-04, 4.13994530e-04, 1.94484370e-04,\n",
       "        1.74148307e-04, 5.35261050e-04, 1.90075270e-04, 5.09753138e-04,\n",
       "        6.40434383e-04, 1.04372062e-04, 6.00940827e-05, 7.89695127e-04,\n",
       "        1.02333631e-04, 1.01630835e-04, 4.06803175e-04, 2.34160916e-04,\n",
       "        1.78400235e-04, 5.80414655e-04, 2.03537683e-04, 1.57999473e-04,\n",
       "        7.00501042e-04, 3.12920490e-04, 3.35097271e-04, 9.00510982e-05]),\n",
       " 'param_learning_rate': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_loss': masked_array(data=['ls', 'ls', 'ls', 'ls', 'ls', 'ls', 'ls', 'ls', 'ls',\n",
       "                    'lad', 'lad', 'lad', 'lad', 'lad', 'lad', 'lad', 'lad',\n",
       "                    'lad', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
       "                    'huber', 'huber', 'huber', 'huber', 'quantile',\n",
       "                    'quantile', 'quantile', 'quantile', 'quantile',\n",
       "                    'quantile', 'quantile', 'quantile', 'quantile', 'ls',\n",
       "                    'ls', 'ls', 'ls', 'ls', 'ls', 'ls', 'ls', 'ls', 'lad',\n",
       "                    'lad', 'lad', 'lad', 'lad', 'lad', 'lad', 'lad', 'lad',\n",
       "                    'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
       "                    'huber', 'huber', 'huber', 'quantile', 'quantile',\n",
       "                    'quantile', 'quantile', 'quantile', 'quantile',\n",
       "                    'quantile', 'quantile', 'quantile', 'ls', 'ls', 'ls',\n",
       "                    'ls', 'ls', 'ls', 'ls', 'ls', 'ls', 'lad', 'lad',\n",
       "                    'lad', 'lad', 'lad', 'lad', 'lad', 'lad', 'lad',\n",
       "                    'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
       "                    'huber', 'huber', 'huber', 'quantile', 'quantile',\n",
       "                    'quantile', 'quantile', 'quantile', 'quantile',\n",
       "                    'quantile', 'quantile', 'quantile'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 2, 2, 2, 4, 4, 4, 1, 1, 1, 2, 2, 2, 4, 4, 4,\n",
       "                    1, 1, 1, 2, 2, 2, 4, 4, 4, 1, 1, 1, 2, 2, 2, 4, 4, 4,\n",
       "                    1, 1, 1, 2, 2, 2, 4, 4, 4, 1, 1, 1, 2, 2, 2, 4, 4, 4,\n",
       "                    1, 1, 1, 2, 2, 2, 4, 4, 4, 1, 1, 1, 2, 2, 2, 4, 4, 4,\n",
       "                    1, 1, 1, 2, 2, 2, 4, 4, 4, 1, 1, 1, 2, 2, 2, 4, 4, 4,\n",
       "                    1, 1, 1, 2, 2, 2, 4, 4, 4, 1, 1, 1, 2, 2, 2, 4, 4, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[100, 150, 200, 100, 150, 200, 100, 150, 200, 100, 150,\n",
       "                    200, 100, 150, 200, 100, 150, 200, 100, 150, 200, 100,\n",
       "                    150, 200, 100, 150, 200, 100, 150, 200, 100, 150, 200,\n",
       "                    100, 150, 200, 100, 150, 200, 100, 150, 200, 100, 150,\n",
       "                    200, 100, 150, 200, 100, 150, 200, 100, 150, 200, 100,\n",
       "                    150, 200, 100, 150, 200, 100, 150, 200, 100, 150, 200,\n",
       "                    100, 150, 200, 100, 150, 200, 100, 150, 200, 100, 150,\n",
       "                    200, 100, 150, 200, 100, 150, 200, 100, 150, 200, 100,\n",
       "                    150, 200, 100, 150, 200, 100, 150, 200, 100, 150, 200,\n",
       "                    100, 150, 200, 100, 150, 200, 100, 150, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.01,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.01,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 150},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200}],\n",
       " 'split0_test_score': array([ 0.68299806,  0.78437793,  0.83233382,  0.6845506 ,  0.78374222,\n",
       "         0.83166981,  0.6777278 ,  0.77780387,  0.82851543,  0.51507483,\n",
       "         0.65315173,  0.72752031,  0.51984632,  0.64929848,  0.72895961,\n",
       "         0.51860834,  0.65034745,  0.7280694 ,  0.63965182,  0.74797849,\n",
       "         0.80451254,  0.63965182,  0.74778971,  0.80422433,  0.6394313 ,\n",
       "         0.74785896,  0.80329753, -0.24628568,  0.09979425,  0.29538233,\n",
       "        -0.23237519,  0.10728392,  0.30696026, -0.21199923,  0.11467098,\n",
       "         0.31051212,  0.89905916,  0.89427632,  0.89923779,  0.89619235,\n",
       "         0.89525178,  0.89878467,  0.88037713,  0.88381332,  0.88547983,\n",
       "         0.88590036,  0.89725896,  0.89939189,  0.88988373,  0.89730295,\n",
       "         0.90177766,  0.88644784,  0.89729588,  0.89870103,  0.89698373,\n",
       "         0.89879693,  0.90177166,  0.89250256,  0.90495296,  0.90061097,\n",
       "         0.90245082,  0.90650481,  0.90584454,  0.72135536,  0.74046528,\n",
       "         0.76038922,  0.75175906,  0.771874  ,  0.79420499,  0.76420205,\n",
       "         0.77575625,  0.78435247,  0.8806683 ,  0.88332473,  0.88481514,\n",
       "         0.87905217,  0.88340056,  0.8821345 ,  0.88229536,  0.88496513,\n",
       "         0.8844886 ,  0.90175727,  0.90130546,  0.9017777 ,  0.90051285,\n",
       "         0.9008411 ,  0.90735227,  0.89840598,  0.89345513,  0.89271755,\n",
       "         0.91087479,  0.90592069,  0.90673482,  0.9054969 ,  0.90426877,\n",
       "         0.90149943,  0.89727432,  0.8982842 ,  0.90061482,  0.77868186,\n",
       "         0.74821929,  0.75931308,  0.7872415 ,  0.79535122,  0.79528585,\n",
       "         0.80186391,  0.80497897,  0.82220141]),\n",
       " 'split1_test_score': array([ 0.65325043,  0.73632121,  0.77258469,  0.65289289,  0.73656641,\n",
       "         0.76762528,  0.65446671,  0.73788336,  0.77127637,  0.47916389,\n",
       "         0.62221611,  0.70871403,  0.4789622 ,  0.62555066,  0.70857743,\n",
       "         0.48158322,  0.62644766,  0.70882399,  0.62963821,  0.74199037,\n",
       "         0.799629  ,  0.63328336,  0.74503222,  0.80154995,  0.63328336,\n",
       "         0.74512301,  0.80200873, -0.11367851,  0.12115527,  0.31246507,\n",
       "        -0.10981741,  0.15373581,  0.3216268 , -0.09743635,  0.15699868,\n",
       "         0.3137045 ,  0.78852275,  0.80957374,  0.80040924,  0.82842201,\n",
       "         0.83583217,  0.83379784,  0.81330697,  0.81623435,  0.81730496,\n",
       "         0.83648933,  0.82570508,  0.82942494,  0.87202052,  0.86443468,\n",
       "         0.85209728,  0.84517017,  0.82436673,  0.82061912,  0.82991588,\n",
       "         0.80084112,  0.81800306,  0.85055293,  0.83380369,  0.83587315,\n",
       "         0.83743819,  0.83585523,  0.83202627,  0.70645265,  0.6921195 ,\n",
       "         0.6978771 ,  0.69121818,  0.70968647,  0.72606825,  0.65478523,\n",
       "         0.67456555,  0.68187799,  0.8049056 ,  0.80752716,  0.80173004,\n",
       "         0.83425316,  0.84288674,  0.84483721,  0.80146785,  0.80186513,\n",
       "         0.80311752,  0.85741148,  0.8621744 ,  0.84286771,  0.85983655,\n",
       "         0.85050161,  0.81772717,  0.84767128,  0.81653429,  0.80689447,\n",
       "         0.85146569,  0.84024934,  0.83731444,  0.83054643,  0.83952749,\n",
       "         0.81944649,  0.79761747,  0.81234993,  0.78274388,  0.6785103 ,\n",
       "         0.68198592,  0.71910067,  0.73213887,  0.69287443,  0.76745901,\n",
       "         0.66746258,  0.68357294,  0.68440967]),\n",
       " 'split2_test_score': array([0.63915905, 0.74093298, 0.79769514, 0.63978743, 0.7427955 ,\n",
       "        0.79822043, 0.62572487, 0.73225969, 0.79156873, 0.40742854,\n",
       "        0.53395098, 0.61840332, 0.40742327, 0.53346188, 0.61520421,\n",
       "        0.41665753, 0.54191773, 0.61525155, 0.53455631, 0.64134428,\n",
       "        0.69956482, 0.5335885 , 0.64136022, 0.69924949, 0.54004876,\n",
       "        0.64896714, 0.7088761 , 0.07049105, 0.32506871, 0.47910418,\n",
       "        0.06989139, 0.32421979, 0.48310917, 0.07818879, 0.33635477,\n",
       "        0.49905774, 0.88525771, 0.88854674, 0.88897602, 0.88749227,\n",
       "        0.89349587, 0.88901335, 0.88839355, 0.89012284, 0.89005465,\n",
       "        0.8221383 , 0.82306002, 0.84269185, 0.81857888, 0.83165529,\n",
       "        0.81647334, 0.81879453, 0.83487062, 0.84252159, 0.88090177,\n",
       "        0.88625488, 0.88597008, 0.88758436, 0.89611757, 0.89475336,\n",
       "        0.85842288, 0.86319638, 0.86613621, 0.82139815, 0.8227382 ,\n",
       "        0.82481988, 0.84529735, 0.85578799, 0.86262531, 0.84101775,\n",
       "        0.85300365, 0.85222804, 0.89292634, 0.89198295, 0.88425487,\n",
       "        0.89354441, 0.88694028, 0.88512788, 0.89035567, 0.88773139,\n",
       "        0.88744809, 0.83683149, 0.82532714, 0.87446527, 0.82386889,\n",
       "        0.85400983, 0.86636385, 0.84300156, 0.84492142, 0.84516636,\n",
       "        0.87001341, 0.87650332, 0.88196563, 0.88461434, 0.89095658,\n",
       "        0.88785457, 0.87070297, 0.86706342, 0.88080745, 0.79381994,\n",
       "        0.81226796, 0.80187963, 0.83849721, 0.84277285, 0.84650865,\n",
       "        0.85223915, 0.85704757, 0.84842485]),\n",
       " 'split3_test_score': array([ 0.66137388,  0.76303631,  0.81082803,  0.66137388,  0.76294654,\n",
       "         0.8104848 ,  0.66198945,  0.76303434,  0.81283898,  0.52628837,\n",
       "         0.6512388 ,  0.72530406,  0.52625996,  0.65169307,  0.72646778,\n",
       "         0.5313281 ,  0.65441325,  0.72758294,  0.64406394,  0.73996613,\n",
       "         0.79322049,  0.64406394,  0.73996613,  0.79316464,  0.64591882,\n",
       "         0.7431626 ,  0.79575779, -0.60119705, -0.15494549,  0.10328355,\n",
       "        -0.58090091, -0.13271752,  0.12438436, -0.59526736, -0.15724879,\n",
       "         0.11443785,  0.89278961,  0.89719103,  0.89949216,  0.89483914,\n",
       "         0.89427826,  0.89935911,  0.87570254,  0.88091016,  0.88084164,\n",
       "         0.88354399,  0.88686451,  0.88605689,  0.87919183,  0.88902355,\n",
       "         0.89577987,  0.88045234,  0.8778071 ,  0.87937592,  0.88871034,\n",
       "         0.8928769 ,  0.88995046,  0.88689151,  0.89201188,  0.89545047,\n",
       "         0.88859301,  0.88926011,  0.89431428,  0.66435429,  0.69055327,\n",
       "         0.68542878,  0.70678803,  0.74461972,  0.74911814,  0.71445552,\n",
       "         0.71593334,  0.76528353,  0.89646014,  0.89689464,  0.89654593,\n",
       "         0.88929446,  0.89194442,  0.89054028,  0.89149374,  0.89101635,\n",
       "         0.8892743 ,  0.87587234,  0.88087831,  0.89039952,  0.87710684,\n",
       "         0.89024005,  0.8905288 ,  0.86627718,  0.86979839,  0.88383004,\n",
       "         0.88767704,  0.89331751,  0.88125792,  0.88722106,  0.88851407,\n",
       "         0.88560192,  0.88203872,  0.88501559,  0.87834669,  0.68577684,\n",
       "         0.71124731,  0.72755116,  0.73131006,  0.70717409,  0.74358824,\n",
       "         0.77895172,  0.7873986 ,  0.78579024]),\n",
       " 'split4_test_score': array([ 0.66240079,  0.75953449,  0.80459413,  0.65293881,  0.75029362,\n",
       "         0.78900338,  0.64067293,  0.72710085,  0.77016824,  0.43220877,\n",
       "         0.55225718,  0.62513935,  0.4394806 ,  0.56047096,  0.62383513,\n",
       "         0.43580671,  0.55843876,  0.62068103,  0.55923332,  0.65500421,\n",
       "         0.70966698,  0.56217536,  0.65564853,  0.70813322,  0.56217536,\n",
       "         0.65556932,  0.70800191, -0.17931147,  0.1096652 ,  0.30194156,\n",
       "        -0.17843733,  0.10383742,  0.27646703, -0.19505913,  0.11492686,\n",
       "         0.28142162,  0.89441507,  0.88832316,  0.88395152,  0.8695839 ,\n",
       "         0.87154151,  0.87156846,  0.85015512,  0.84913307,  0.8498484 ,\n",
       "         0.77491763,  0.79247064,  0.80300733,  0.7711054 ,  0.76663744,\n",
       "         0.79813925,  0.77898904,  0.8021232 ,  0.77772238,  0.82043127,\n",
       "         0.86849226,  0.87014683,  0.79566627,  0.79809161,  0.82465955,\n",
       "         0.77353456,  0.77848384,  0.77786366,  0.66458119,  0.67386308,\n",
       "         0.7078197 ,  0.6874468 ,  0.69153116,  0.70335209,  0.6867557 ,\n",
       "         0.6901388 ,  0.69539502,  0.89782054,  0.88217282,  0.89431997,\n",
       "         0.86180622,  0.86361512,  0.86193971,  0.842434  ,  0.83985101,\n",
       "         0.84131903,  0.78497093,  0.7941021 ,  0.81870362,  0.75234438,\n",
       "         0.73648536,  0.8104806 ,  0.76306854,  0.78778105,  0.78834361,\n",
       "         0.88272613,  0.87556947,  0.86384439,  0.80102807,  0.81281174,\n",
       "         0.83088222,  0.80857836,  0.78757367,  0.81306311,  0.65777073,\n",
       "         0.66350043,  0.67839168,  0.68577048,  0.69413968,  0.66927959,\n",
       "         0.66317739,  0.66872441,  0.69210094]),\n",
       " 'mean_test_score': array([ 0.65983644,  0.75684059,  0.80360716,  0.65830872,  0.75526886,\n",
       "         0.79940074,  0.65211635,  0.74761642,  0.79487355,  0.47203288,\n",
       "         0.60256296,  0.68101622,  0.47439447,  0.60409501,  0.68060883,\n",
       "         0.47679678,  0.60631297,  0.68008178,  0.60142872,  0.70525669,\n",
       "         0.76131877,  0.6025526 ,  0.70595936,  0.76126433,  0.60417152,\n",
       "         0.70813621,  0.76358841, -0.21399633,  0.10014759,  0.29843534,\n",
       "        -0.20632789,  0.11127188,  0.30250952, -0.20431466,  0.1131405 ,\n",
       "         0.30382676,  0.87200886,  0.8755822 ,  0.87441335,  0.87530594,\n",
       "         0.87807992,  0.87850469,  0.86158706,  0.86404275,  0.8647059 ,\n",
       "         0.84059792,  0.84507184,  0.85211458,  0.84615607,  0.84981078,\n",
       "         0.85285348,  0.84197078,  0.84729271,  0.84378801,  0.8633886 ,\n",
       "         0.86945242,  0.87316841,  0.86263952,  0.86499554,  0.8702695 ,\n",
       "         0.85208789,  0.85466007,  0.85523699,  0.71562833,  0.72394787,\n",
       "         0.73526693,  0.73650188,  0.75469987,  0.76707375,  0.73224325,\n",
       "         0.74187952,  0.75582741,  0.87455618,  0.87238046,  0.87233319,\n",
       "         0.87159008,  0.87375743,  0.87291592,  0.86160933,  0.8610858 ,\n",
       "         0.86112951,  0.8513687 ,  0.85275748,  0.86564277,  0.8427339 ,\n",
       "         0.84641559,  0.85849054,  0.84368491,  0.84249806,  0.84339041,\n",
       "         0.88055141,  0.87831207,  0.87422344,  0.86178136,  0.86721573,\n",
       "         0.86505693,  0.85124237,  0.85005736,  0.85111519,  0.71891193,\n",
       "         0.72344418,  0.73724725,  0.75499162,  0.74646245,  0.76442427,\n",
       "         0.75273895,  0.7603445 ,  0.76658542]),\n",
       " 'std_test_score': array([0.01425714, 0.01719329, 0.01936844, 0.01482725, 0.01673199,\n",
       "        0.02136973, 0.01781242, 0.01949587, 0.02294617, 0.04605822,\n",
       "        0.05010605, 0.0488545 , 0.04578402, 0.04829362, 0.05044621,\n",
       "        0.0448145 , 0.04711001, 0.05121854, 0.04544648, 0.04688148,\n",
       "        0.04654579, 0.04567339, 0.04719567, 0.0472332 , 0.04406585,\n",
       "        0.04568813, 0.04510233, 0.22052971, 0.15244279, 0.11911667,\n",
       "        0.21324758, 0.14611776, 0.11437508, 0.22100674, 0.15802788,\n",
       "        0.12217   , 0.04197871, 0.03317812, 0.03748294, 0.02528691,\n",
       "        0.02290211, 0.0245089 , 0.02732236, 0.02779747, 0.02757561,\n",
       "        0.04139617, 0.04024078, 0.03578367, 0.04486768, 0.04744351,\n",
       "        0.04136178, 0.03993273, 0.03507603, 0.04286026, 0.03175623,\n",
       "        0.03577866, 0.02938031, 0.03669797, 0.04181896, 0.03291663,\n",
       "        0.04537493, 0.04497632, 0.04632995, 0.05751363, 0.05416472,\n",
       "        0.05154813, 0.05900706, 0.05767471, 0.05644557, 0.06517442,\n",
       "        0.06538758, 0.06215588, 0.03534696, 0.0328841 , 0.03564381,\n",
       "        0.02163742, 0.01818466, 0.01705065, 0.03502009, 0.03502585,\n",
       "        0.03402437, 0.03948657, 0.03854671, 0.03071955, 0.0516499 ,\n",
       "        0.05838107, 0.03858112, 0.04476642, 0.03745897, 0.04107015,\n",
       "        0.01965726, 0.02212223, 0.02296264, 0.03936027, 0.03497601,\n",
       "        0.0332208 , 0.04035324, 0.04280928, 0.04515749, 0.05595021,\n",
       "        0.05284747, 0.04135586, 0.05270269, 0.06134937, 0.05862788,\n",
       "        0.07522499, 0.07261372, 0.06702305]),\n",
       " 'rank_test_score': array([ 88,  65,  55,  89,  67,  56,  90,  71,  57,  99,  94,  85,  98,\n",
       "         93,  86,  97,  91,  87,  96,  84,  62,  95,  83,  63,  92,  82,\n",
       "         61, 108, 105, 102, 107, 104, 101, 106, 103, 100,  15,   5,   8,\n",
       "          6,   4,   2,  29,  24,  23,  54,  47,  37,  46,  43,  35,  53,\n",
       "         44,  48,  25,  18,  11,  26,  22,  17,  38,  34,  33,  81,  78,\n",
       "         76,  75,  69,  58,  77,  73,  66,   7,  13,  14,  16,  10,  12,\n",
       "         28,  31,  30,  39,  36,  20,  51,  45,  32,  49,  52,  50,   1,\n",
       "          3,   9,  27,  19,  21,  40,  42,  41,  80,  79,  74,  68,  72,\n",
       "         60,  70,  64,  59], dtype=int32)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg2.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.2, loss='huber')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB was better so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply model to test data for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-c87c188a67fd>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bsmt_data['BsmtQual'] = encoder1.fit_transform(bsmt_data['BsmtQual'].to_numpy().reshape(-1,1))\n",
      "/home/aaron/ml/env/lib/python3.8/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-6b9d36868d47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-c87c188a67fd>\u001b[0m in \u001b[0;36mclean_data\u001b[0;34m(Data)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mone_hot_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     temp = pd.DataFrame(\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mone_hot_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mone_hot_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mone_hot_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     )\n",
      "\u001b[0;32m~/ml/env/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \"\"\"\n\u001b[1;32m    409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/env/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \"\"\"\n\u001b[1;32m    384\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_idx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_drop_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/env/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, handle_unknown)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mX_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/env/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mXi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             Xi = check_array(Xi, ensure_2d=False, dtype=None,\n\u001b[0m\u001b[1;32m     61\u001b[0m                              force_all_finite=needs_validation)\n\u001b[1;32m     62\u001b[0m             \u001b[0mX_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    646\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input contains NaN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "Test = pd.read_csv('test.csv')\n",
    "\n",
    "Test = clean_data(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
