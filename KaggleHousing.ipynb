{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# custom modules\n",
    "from custom_modules import custom_plot, custom_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreProcessor:\n",
    "    '''\n",
    "    Class with methods to impute, encode, and/or transform methods used to \n",
    "    pre-process data \n",
    "    '''\n",
    "    def __init__(self, dataframe, target):\n",
    "        self.df = dataframe # original unchanged df used for fitting encoders, etc.\n",
    "        self.X  = dataframe.drop(target, axis=1)\n",
    "        self.y  = dataframe[target]\n",
    "        self.features  = self.X.columns\n",
    "        \n",
    "        # Remove rows with missing target, separate target from predictors\n",
    "        missing = self.y[self.y.isnull()].index.tolist()     \n",
    "        self.df.drop(missing, inplace=True)\n",
    "        self.X.drop(missing, inplace=True)\n",
    "        self.y.drop(missing, inplace=True)\n",
    "        \n",
    "        \n",
    "    def log_transform_target(self):        \n",
    "        self.y = np.log1p(self.y)\n",
    "        self.df[self.y.name] = self.y\n",
    "    \n",
    "    def drop_missing(self, threshold=0.85,  X=None, verbose=False):\n",
    "        '''\n",
    "        Drop columns missing more than *threshold*% of its values\n",
    "        @param threshold: (float)\n",
    "        '''\n",
    "        X = self.X if X is None else X\n",
    "        \n",
    "        # ------------------------------------------------------------------------------------------ #\n",
    "        # For the Kaggle Housing data, some features are intended to have 'NA' as a category, \n",
    "        # so change the pd.NA for those to 'NA' where necessary\n",
    "        na_allowed = ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
    "                       'BsmtFinType2', 'FireplaceQu', 'GarageType', 'GarageFinish', \n",
    "                       'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "\n",
    "        for feature in na_allowed:\n",
    "            self.df[feature].fillna('NA', inplace=True)\n",
    "            X[feature].fillna('NA', inplace=True)\n",
    "            \n",
    "        # ------------------------------------------------------------------------------------------ #\n",
    "        # Number/proportion of missing values in each column of training data\n",
    "        missing_val_count_by_column = (self.df.isnull().sum())\n",
    "        missing_val_prop_by_column  = (self.df.isnull().mean())\n",
    "\n",
    "        # Drop columns missing more than n% of values\n",
    "        to_drop = missing_val_prop_by_column[missing_val_prop_by_column > threshold].index.values\n",
    "        \n",
    "        X.drop(to_drop, axis=1, inplace=True)\n",
    "        self.features = X.columns\n",
    "        if verbose: \n",
    "            print(f\"TOTALS:\\n{missing_val_count_by_column[missing_val_count_by_column > 0]}\\n\")\n",
    "            print(f\"PROPORTIONS:\\n{missing_val_prop_by_column[missing_val_prop_by_column > 0]}\\n\")\n",
    "            print(f\"DROPPED: {to_drop}\\n\")\n",
    "                  \n",
    "    def impute(self, X=None):\n",
    "        '''\n",
    "        Impute missing values \n",
    "        \n",
    "        @param \n",
    "        '''\n",
    "        X = self.X if X is None else X\n",
    "        \n",
    "        for feature in self.features:\n",
    "            if X[feature].dtype == \"object\":\n",
    "                # fill categorical columns with most frequent value\n",
    "                X[feature].fillna( self.df[feature].mode().iloc[0], inplace=True )\n",
    "            else:\n",
    "                # filling missing values with medians of the columns\n",
    "                X[feature].fillna( self.df[feature].median(), inplace=True )\n",
    "    \n",
    "    def encode(self, encoder, args, col, X=None):\n",
    "        '''\n",
    "        Encode the categorical variables in the dataset using the encoder passed in\n",
    "        \n",
    "        @param encoder: type of encoder to use\n",
    "        @param args: list of arguments used to fit & transform the column\n",
    "        @return: \n",
    "        '''\n",
    "        X = self.X if X is None else X\n",
    "        \n",
    "        encoder.fit(*args)\n",
    "        X[col] = encoder.transform(X[col])\n",
    "    \n",
    "    def feature_engineering(self, X=None):\n",
    "        '''\n",
    "        dataset specific feature engineering\n",
    "        '''\n",
    "        X = self.X if X is None else X\n",
    "        \n",
    "        X['TotalBath'] = X['BsmtFullBath'] + X['FullBath'] + ((X['BsmtHalfBath']  + X['HalfBath']) / 2)\n",
    "        X.drop(['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath'], axis=1, inplace=True)\n",
    "        \n",
    "        # Age = (Most Recent Yr in All Data) - (Yr House was Last Remod.)\n",
    "        X['Age'] = X['YearRemodAdd'].max() - X['YearRemodAdd']\n",
    "        \n",
    "        X['ExterAggr'] = X['ExterQual'] + X['ExterCond']\n",
    "        X.drop(['ExterQual', 'ExterCond'], axis=1, inplace=True)\n",
    "        \n",
    "        X['BsmtAggr'] = X['BsmtQual'] + X['BsmtCond'] + X['BsmtExposure'] + ((X['BsmtFinType1'] + X['BsmtFinType2']) / 2)\n",
    "        X.drop(['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'], axis=1, inplace=True)\n",
    "        \n",
    "        X['GarageAggr'] = X['GarageFinish'] + X['GarageQual'] + X['GarageCond']\n",
    "        X.drop(['GarageFinish', 'GarageQual', 'GarageCond'], axis=1, inplace=True)\n",
    "        \n",
    "        X['TotalSF'] = X['TotalBsmtSF'] + X['GrLivArea']\n",
    "        X.drop(['TotalBsmtSF', 'GrLivArea', '1stFlrSF', '2ndFlrSF'], axis=1, inplace=True)\n",
    "        \n",
    "        self.features = X.columns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X_train, X_valid, y_train, y_valid, model, err_func):\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return err_func(y_valid, preds)\n",
    "\n",
    "def score_log_dataset(X_train, X_valid, y_train, y_valid, model, err_func):\n",
    "    model.fit(X_train, y_train)\n",
    "    preds   = np.expm1(model.predict(X_valid))\n",
    "    y_valid = np.expm1(y_valid)\n",
    "    return err_func(y_valid, preds)\n",
    "\n",
    "def feature_importances(model, columns):\n",
    "    feat_imp = { columns[i]: model.feature_importances_[i] for i in range(len(columns)) }\n",
    "    return dict(sorted(feat_imp.items(), key=lambda item: item[1], reverse=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df_train = pd.read_csv('data/train.csv', index_col=\"Id\")\n",
    "df_test = pd.read_csv('data/test.csv', index_col=\"Id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Distribution of Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sale Price Distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "ax1.hist(df_train.SalePrice, bins=100)\n",
    "ax1.set_xlabel(\"SalePrice\")\n",
    "ax1.set_title(\"Sale Price Histogram\")\n",
    "\n",
    "ax2.hist(np.log1p(df_train.SalePrice), bins=100)\n",
    "ax2.set_xlabel(\"log(SalePrice)\")\n",
    "ax2.set_title(\"log(Sale Price) Histogram\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Preprocess Data & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_map = { \n",
    "    'MSSubClass': 'RankLabelEncoder',\n",
    "    'MSZoning': 'RankLabelEncoder',\n",
    "    'Street': 'RankLabelEncoder',\n",
    "    'Alley': 'RankLabelEncoder',\n",
    "    'LotShape': 'custom',\n",
    "    'LandContour': 'RankLabelEncoder',\n",
    "    'Utilities': 'custom',\n",
    "    'LotConfig': 'RankLabelEncoder',\n",
    "    'LandSlope': 'RankLabelEncoder',\n",
    "    'Neighborhood': 'RankLabelEncoder',\n",
    "    'Condition1': 'RankLabelEncoder',\n",
    "    'Condition2': 'RankLabelEncoder',\n",
    "    'BldgType': 'RankLabelEncoder',\n",
    "    'HouseStyle': 'RankLabelEncoder',\n",
    "    'RoofStyle': 'RankLabelEncoder',\n",
    "    'RoofMatl': 'RankLabelEncoder',\n",
    "    'Exterior1st': 'RankLabelEncoder',\n",
    "    'Exterior2nd': 'RankLabelEncoder',\n",
    "    'MasVnrType': 'RankLabelEncoder',\n",
    "    'ExterQual': 'custom',\n",
    "    'ExterCond': 'custom',\n",
    "    'Foundation': 'RankLabelEncoder',\n",
    "    'BsmtQual': 'custom',\n",
    "    'BsmtCond': 'custom',\n",
    "    'BsmtExposure': 'custom',\n",
    "    'BsmtFinType1': 'custom',\n",
    "    'BsmtFinType2': 'custom',\n",
    "    'Heating': 'RankLabelEncoder',\n",
    "    'HeatingQC': 'custom',\n",
    "    'CentralAir': 'custom',\n",
    "    'Electrical': 'custom',\n",
    "    'KitchenQual': 'custom',\n",
    "    'Functional': 'custom',\n",
    "    'FireplaceQu': 'custom',\n",
    "    'GarageType': 'RankLabelEncoder',\n",
    "    'GarageFinish': 'custom',\n",
    "    'GarageQual': 'custom',\n",
    "    'GarageCond': 'custom',\n",
    "    'PavedDrive': 'custom',\n",
    "    'PoolQC': 'custom',\n",
    "    'Fence': 'custom',\n",
    "    'MiscFeature': 'RankLabelEncoder',\n",
    "    'SaleType': 'RankLabelEncoder',\n",
    "    'SaleCondition': 'RankLabelEncoder',\n",
    "}\n",
    "\n",
    "# order for features where the order can be inferred by the categories\n",
    "custom_map = {\n",
    "    'LotShape': {'IR3': 0, 'IR2': 1, 'IR1': 2, 'Reg': 3},\n",
    "    'Utilities': {'AllPub': 0, 'NoSewr': 1, 'NoSeWa': 2, 'ELO': 3},\n",
    "    'ExterQual': {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    'ExterCond': {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    'BsmtQual': {'NA': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'BsmtCond': {'NA': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'BsmtExposure': {'NA': 0, 'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4},\n",
    "    'BsmtFinType1': {'NA': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n",
    "    'BsmtFinType2': {'NA': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n",
    "    'HeatingQC': {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    'CentralAir': {'N': 0, 'Y': 1},\n",
    "    'Electrical': {'FuseP': 0, 'FuseF': 1, 'Mix': 2, 'FuseA': 3, 'SBrkr': 4},\n",
    "    'KitchenQual': {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    'Functional': {'Sal': 0, 'Sev': 1, 'Maj2': 2, 'Maj1': 3,'Mod': 4, 'Min2': 5, 'Min1': 6,'Typ': 7},\n",
    "    'FireplaceQu': {'NA': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'GarageFinish': {'NA': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3},\n",
    "    'GarageQual': {'NA': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'GarageCond': {'NA': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'PavedDrive': {'N': 0, 'P': 1, 'Y': 2},\n",
    "    'PoolQC': {'NA': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    'Fence': {'NA': 0, 'MnWw': 1, 'MnPrv': 2, 'GdWo': 3, 'GdPrv': 4}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = df_train.copy()\n",
    "preprocess = DataPreProcessor(train, 'SalePrice')\n",
    "\n",
    "preprocess.drop_missing(threshold=1, verbose=True)\n",
    "preprocess.impute()\n",
    "preprocess.log_transform_target()\n",
    "\n",
    "# --------------------------------- Plot Data Distributions -------------------------------- #\n",
    "print('---------------------------------------\\n\\nINTERACTIVE PLOTS OF DATA DISTRIBUTIONS (pre-encoding)')\n",
    "preprocess_df = pd.concat([preprocess.X, preprocess.y], axis=1)\n",
    "custom_plot.interactive_distributions(preprocess_df, preprocess.y.name);\n",
    "# ------------------------------------------------------------------------------------------ #\n",
    "\n",
    "rle = custom_encoder.RankLabelEncoder()\n",
    "for col,encoder in encoder_map.items():\n",
    "    if encoder == 'RankLabelEncoder':\n",
    "        preprocess.encode( rle, [preprocess.df[col], preprocess.df[preprocess.y.name]], col )\n",
    "    else: # == 'custom' \n",
    "        preprocess.X[col].replace( custom_map[col], inplace=True )\n",
    "\n",
    "# preprocess.feature_engineering()\n",
    "   \n",
    "X, y  = preprocess.X, preprocess.y   \n",
    "train = pd.concat([X, y], axis=1)\n",
    "\n",
    "# --------------------------------- Plot Data Distributions -------------------------------- #\n",
    "print('---------------------------------------\\n\\nINTERACTIVE PLOTS OF DATA DISTRIBUTIONS (post-encoding)')\n",
    "preprocess_df = pd.concat([preprocess.X, preprocess.y], axis=1)\n",
    "custom_plot.interactive_distributions(preprocess_df, preprocess.y.name);\n",
    "# ------------------------------------------------------------------------------------------ #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_plot.interactive_heatmap(train, 'SalePrice');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Models\n",
    "rs = 42\n",
    "\n",
    "base_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=rs),\n",
    "    'Random Forest': RandomForestRegressor(random_state=rs),\n",
    "    'Gradient Boost': GradientBoostingRegressor(random_state=rs),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train/validation splits\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=rs)\n",
    "\n",
    "# --------------------------------------- TRAINING ERROR ----------------------------------------------------- #\n",
    "data = {}\n",
    "for model_name, model in base_models.items():\n",
    "    # regular sale price predictions/score\n",
    "    MAE = score_log_dataset(X_train, X_train, y_train, y_train, model, mean_absolute_error)\n",
    "    MSE = score_log_dataset(X_train, X_train, y_train, y_train, model, mean_squared_error)\n",
    "\n",
    "    data[model_name] = [MAE, MSE]\n",
    "\n",
    "    \n",
    "print('BASELINE TRAINING ERRORS:')\n",
    "print(pd.DataFrame.from_dict(data, orient='index', columns=['MAE', 'MSE']))\n",
    "print()\n",
    "# ------------------------------------------------------------------------------------------------------------ #\n",
    "\n",
    "# --------------------------------------- VALIDATION ERROR --------------------------------------------------- #\n",
    "data = {}\n",
    "for model_name, model in base_models.items():\n",
    "    # regular sale price predictions/score\n",
    "    MAE = score_log_dataset(X_train, X_valid, y_train, y_valid, model, mean_absolute_error)\n",
    "    MSE = score_log_dataset(X_train, X_valid, y_train, y_valid, model, mean_squared_error)\n",
    "\n",
    "    data[model_name] = [MAE, MSE]\n",
    "\n",
    "    \n",
    "print('BASELINE VALIDATION ERRORS:')\n",
    "print(pd.DataFrame.from_dict(data, orient='index', columns=['MAE', 'MSE']))\n",
    "# ------------------------------------------------------------------------------------------------------------ #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Process test data\n",
    "X_test = df_test.copy()\n",
    "preprocess.drop_missing(threshold=1, X=X_test, verbose=True)\n",
    "preprocess.impute(X_test)\n",
    "\n",
    "rle = custom_encoder.RankLabelEncoder()\n",
    "for col,encoder in encoder_map.items():\n",
    "    if encoder == 'RankLabelEncoder':\n",
    "        preprocess.encode( rle, [preprocess.df[col], preprocess.df[preprocess.y.name]], col, X_test )\n",
    "    else: # == 'custom' \n",
    "        X_test[col].replace( custom_map[col], inplace=True )\n",
    "\n",
    "# preprocess.feature_engineering(X_test)\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection (corr >= corr_thresholds)\n",
    "threshold = 0.0 # not seeing any improvement from holding out columns, if anything it seems worse\n",
    "# features = corr[abs(corr.SalePrice) >= threshold].index.values\n",
    "\n",
    "model = base_models['Gradient Boost']\n",
    "model.set_params(loss='ls', max_features='auto', n_estimators=250)\n",
    "model.fit(X, y)\n",
    "\n",
    "# preds = model.predict(X_test)\n",
    "preds = np.expm1(model.predict(X_test))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds})\n",
    "output.to_csv('submission2.csv', index=False)\n",
    "\n",
    "# SCORE -> 0.12721 (1422/5721, top 25%)\n",
    "# no feature engineering or dropping\n",
    "#\n",
    "# SCORE -> 0.12811\n",
    "# w/ some feature engineering (no 'ExterAggr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances(model, X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip-compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
